# banditproblem
A study on Multi-armed bandit problem
## Members
* K.Zhou
* X.Sun
## Expected Algorithms
* epislon greedy
* epislon first
* epislon decreasing
* UCB
## Works
### Bandit (K.Zhou)
* Bernoulli Bandit √
  * Initial the parameters of Bernoulli distribution
  * Pull and return a reward
* Gaussian Bandit √
  * Initial the parameters of Bernoulli distribution
  * Pull and return a reward
* Multiarmed Bandit
  * Initial the type (Bernoulli, Gaussian) and arm numbers
  * Pull one specific arm and return a reward
### Epsilon Algorithm (X.Sun)
* Epsilon First
* Epsilon Greedy
* Epsilon Decresing
### Other Algorithms
* UCB
## Test Sample
* Initial a ten armed Bernoulli Bandit with random distribution, and print the parameters of these bandit
* Run different algorithms and return reward with the best bandit





